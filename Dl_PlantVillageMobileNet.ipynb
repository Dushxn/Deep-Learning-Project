{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dushxn/Deep-Learning-Project/blob/Shaini-Dev/Dl_PlantVillageMobileNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3O0vZWudetB",
        "outputId": "2bf93ca9-3ea4-418f-db46-349d2b33ecd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "import os, pathlib, random, itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Plantvillage Dataset**"
      ],
      "metadata": {
        "id": "eA_lAQo4eqpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to your zip file in Drive\n",
        "zip_path = \"/content/drive/MyDrive/DataSet/plantvillage.zip\"\n",
        "\n",
        "# Unzip into /content (fastest for Colab)\n",
        "!unzip -q \"$zip_path\" -d /content/\n",
        "\n",
        "# Check extracted folder name (sometimes it's \"PlantVillage\" or similar)\n",
        "!ls /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXbr9sbXdpVM",
        "outputId": "45f8b04d-48a2-4ac8-a504-9e5b53676146"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " drive\t'plantvillage dataset'\t sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pathlib\n",
        "\n",
        "DATA_DIR = \"/content/plantvillage dataset\"   # change if the extracted folder name differs\n",
        "assert os.path.exists(DATA_DIR), \"Check folder name after unzip!\"\n",
        "print(\"Dataset root:\", DATA_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37_4524Xd85h",
        "outputId": "63af175f-1c9f-43ce-d34b-f785a55c0856"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset root: /content/plantvillage dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset Analysis**"
      ],
      "metadata": {
        "id": "fMhYy0Zje-Mq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "inspect folder structure and counts"
      ],
      "metadata": {
        "id": "wWS9NoMXfQhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root = pathlib.Path(DATA_DIR)\n",
        "# If dataset has 'train'/'test' folders or 'plant_village' etc, adapt this snippet.\n",
        "# We'll assume images are organized in subfolders per class:\n",
        "classes = [p.name for p in root.iterdir() if p.is_dir()]\n",
        "classes = sorted(classes)\n",
        "print(f\"Found {len(classes)} classes.\")\n",
        "for c in classes[:30]:\n",
        "    cnt = len(list(root.joinpath(c).glob('*')))\n",
        "    print(f\"{c}: {cnt} images\")\n"
      ],
      "metadata": {
        "id": "F8AaS7gVeaBt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22c27d91-4f83-4238-89e4-27fee4c0760a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3 classes.\n",
            "color: 38 images\n",
            "grayscale: 38 images\n",
            "segmented: 38 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "visualize class distribution (bar plot)"
      ],
      "metadata": {
        "id": "fLx0VACyfV_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts = {}\n",
        "for c in classes:\n",
        "    counts[c] = len(list(root.joinpath(c).glob('*')))\n",
        "counts_df = pd.DataFrame.from_dict(counts, orient='index', columns=['count']).sort_values('count', ascending=False)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=counts_df['count'].values, y=counts_df.index)\n",
        "plt.title(\"Images per Class\")\n",
        "plt.xlabel(\"Number of images\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BfAjL3x_e16s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "9206f527-2bac-46ca-88b7-b69839fd8fbd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "show sample images per class"
      ],
      "metadata": {
        "id": "kpjqFnLUffKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.image as mpimg\n",
        "def show_samples(classes, n_per_class=3, img_size=(224,224)):\n",
        "    plt.figure(figsize=(n_per_class*3, len(classes)*3))\n",
        "    i = 1\n",
        "    for row, c in enumerate(classes):\n",
        "        # Filter out directories and only include files\n",
        "        imgs = [p for p in root.joinpath(c).glob('*') if p.is_file()][:n_per_class]\n",
        "        for col, img_path in enumerate(imgs):\n",
        "            ax = plt.subplot(len(classes), n_per_class, i)\n",
        "            img = mpimg.imread(img_path)\n",
        "            plt.imshow(img)\n",
        "            ax.set_title(c if col==0 else \"\")\n",
        "            ax.axis('off')\n",
        "            i += 1\n",
        "    plt.tight_layout()\n",
        "# show top 6 classes to avoid huge plot\n",
        "show_samples(list(counts_df.index[:6]), n_per_class=4)"
      ],
      "metadata": {
        "id": "SUWotz66fZFn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4741dc8f-19ae-4a84-ae8e-84b7045c7bf1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x900 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Preprocessing**"
      ],
      "metadata": {
        "id": "xQdrSzOkmijy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define key parameters\n",
        "IMG_SIZE = (124, 124) # A standard size for many CNNs\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Create the training dataset (80% of the data)\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  DATA_DIR,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123, # Seed for reproducibility\n",
        "  image_size=IMG_SIZE,\n",
        "  batch_size=BATCH_SIZE)\n",
        "\n",
        "# Create the validation dataset (20% of the data)\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  DATA_DIR,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=IMG_SIZE,\n",
        "  batch_size=BATCH_SIZE)\n",
        "\n",
        "# Get the class names (they are inferred in alphabetical order by the function)\n",
        "class_names = train_ds.class_names\n",
        "print(\"Class names:\", class_names)"
      ],
      "metadata": {
        "id": "pJfkMwF8frFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "041d90cb-4ad0-4d1d-943b-c0d45604232c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 162916 files belonging to 3 classes.\n",
            "Using 130333 files for training.\n",
            "Found 162916 files belonging to 3 classes.\n",
            "Using 32583 files for validation.\n",
            "Class names: ['color', 'grayscale', 'segmented']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuring for Performance"
      ],
      "metadata": {
        "id": "CmYk55ZjmvEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This version streams from disk and uses much less RAM\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "zbGD9_Fpmnp2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation"
      ],
      "metadata": {
        "id": "nzH3_uGhmzxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a data augmentation layer\n",
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "4tFFqMNSmy7l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Models Below"
      ],
      "metadata": {
        "id": "UkJQGyqWAESC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Required Libraries (extra)"
      ],
      "metadata": {
        "id": "Td6DqYZLSrq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
      ],
      "metadata": {
        "id": "_yYaGt02StBp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🌿 Step 2 — Prepare Preprocessing Layer for MobileNet\n",
        "\n",
        "MobileNetV2 expects inputs scaled between -1 and 1, so we’ll include that preprocessing layer."
      ],
      "metadata": {
        "id": "3kgDedASS0Jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n"
      ],
      "metadata": {
        "id": "3PAcbAFZSwqx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🌿 Step 3 — Build the MobileNetV2 Model (Lightweight CNN)"
      ],
      "metadata": {
        "id": "cc5-n23JS5Yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SHAPE = (124, 124, 3)\n",
        "\n",
        "# Load pre-trained base model\n",
        "base_model = MobileNetV2(\n",
        "    input_shape=IMG_SHAPE,\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# Freeze base model layers (initially)\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build the model\n",
        "inputs = keras.Input(shape=IMG_SHAPE)\n",
        "x = data_augmentation(inputs)           # Use your augmentation layer\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)       # Ensure batchnorm layers are not updated\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(len(class_names), activation='softmax')(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "hV4WYKXxS8hm",
        "outputId": "b7d571bb-3d5c-40d0-9a0d-70eb31deddd7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3016983550.py:4: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ true_divide (\u001b[38;5;33mTrueDivide\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ subtract (\u001b[38;5;33mSubtract\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m327,936\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m771\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ true_divide (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TrueDivide</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ subtract (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">771</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,586,691\u001b[0m (9.87 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,586,691</span> (9.87 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m328,707\u001b[0m (1.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">328,707</span> (1.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🌿 Step 4 — Compile the Model"
      ],
      "metadata": {
        "id": "Y0mwVMknTGpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "UBF42cx_TKcw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🌿 Step 5 — Train the Model\n",
        "\n",
        "We’ll use EarlyStopping and ModelCheckpoint to save the best version."
      ],
      "metadata": {
        "id": "SiJjurddTO65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint(\"mobilenet_best.h5\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stop, checkpoint],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q17oEsWTRxo",
        "outputId": "2e897f3c-5029-44fa-8bf6-21658765877e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9642 - loss: 0.1023\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97839, saving model to mobilenet_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 25ms/step - accuracy: 0.9642 - loss: 0.1023 - val_accuracy: 0.9784 - val_loss: 0.0465\n",
            "Epoch 2/20\n",
            "\u001b[1m8145/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9758 - loss: 0.0596\n",
            "Epoch 2: val_accuracy did not improve from 0.97839\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 25ms/step - accuracy: 0.9758 - loss: 0.0596 - val_accuracy: 0.9770 - val_loss: 0.0521\n",
            "Epoch 3/20\n",
            "\u001b[1m8145/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9779 - loss: 0.0549\n",
            "Epoch 3: val_accuracy improved from 0.97839 to 0.97938, saving model to mobilenet_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 24ms/step - accuracy: 0.9779 - loss: 0.0549 - val_accuracy: 0.9794 - val_loss: 0.0462\n",
            "Epoch 4/20\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9780 - loss: 0.0531\n",
            "Epoch 4: val_accuracy improved from 0.97938 to 0.98137, saving model to mobilenet_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 24ms/step - accuracy: 0.9780 - loss: 0.0531 - val_accuracy: 0.9814 - val_loss: 0.0434\n",
            "Epoch 5/20\n",
            "\u001b[1m8145/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9782 - loss: 0.0518\n",
            "Epoch 5: val_accuracy did not improve from 0.98137\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 24ms/step - accuracy: 0.9782 - loss: 0.0518 - val_accuracy: 0.9805 - val_loss: 0.0416\n",
            "Epoch 6/20\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9789 - loss: 0.0505\n",
            "Epoch 6: val_accuracy did not improve from 0.98137\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 24ms/step - accuracy: 0.9789 - loss: 0.0505 - val_accuracy: 0.9802 - val_loss: 0.0457\n",
            "Epoch 7/20\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9788 - loss: 0.0502\n",
            "Epoch 7: val_accuracy improved from 0.98137 to 0.98183, saving model to mobilenet_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 24ms/step - accuracy: 0.9788 - loss: 0.0502 - val_accuracy: 0.9818 - val_loss: 0.0435\n",
            "Epoch 8/20\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9791 - loss: 0.0507\n",
            "Epoch 8: val_accuracy did not improve from 0.98183\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 24ms/step - accuracy: 0.9791 - loss: 0.0507 - val_accuracy: 0.9775 - val_loss: 0.0449\n",
            "Epoch 9/20\n",
            "\u001b[1m8143/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9779 - loss: 0.0509\n",
            "Epoch 9: val_accuracy did not improve from 0.98183\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 25ms/step - accuracy: 0.9779 - loss: 0.0509 - val_accuracy: 0.9811 - val_loss: 0.0429\n",
            "Epoch 10/20\n",
            "\u001b[1m8145/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9788 - loss: 0.0513\n",
            "Epoch 10: val_accuracy did not improve from 0.98183\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 24ms/step - accuracy: 0.9788 - loss: 0.0513 - val_accuracy: 0.9803 - val_loss: 0.0461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🌿 Step 6 — Fine-Tuning (Optional but boosts accuracy)\n",
        "\n",
        "After initial training, unfreeze some top layers to allow learning more plant-specific features."
      ],
      "metadata": {
        "id": "rD9DOjpEcP7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "# Fine-tune from this layer onward\n",
        "fine_tune_at = 100\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "fine_tune_history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAnGYCiBcTp8",
        "outputId": "e0b38bbc-107a-4f44-8aa6-6995e6bd6871"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 43ms/step - accuracy: 0.9505 - loss: 0.1728 - val_accuracy: 0.9804 - val_loss: 0.0407\n",
            "Epoch 2/10\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 43ms/step - accuracy: 0.9778 - loss: 0.0524 - val_accuracy: 0.9822 - val_loss: 0.0374\n",
            "Epoch 3/10\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 44ms/step - accuracy: 0.9810 - loss: 0.0426 - val_accuracy: 0.9832 - val_loss: 0.0351\n",
            "Epoch 4/10\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 43ms/step - accuracy: 0.9829 - loss: 0.0356 - val_accuracy: 0.9829 - val_loss: 0.0351\n",
            "Epoch 5/10\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 45ms/step - accuracy: 0.9831 - loss: 0.0322 - val_accuracy: 0.9824 - val_loss: 0.0353\n",
            "Epoch 6/10\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 45ms/step - accuracy: 0.9847 - loss: 0.0311 - val_accuracy: 0.9846 - val_loss: 0.0321\n",
            "Epoch 7/10\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 44ms/step - accuracy: 0.9842 - loss: 0.0292 - val_accuracy: 0.9834 - val_loss: 0.0332\n",
            "Epoch 8/10\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 43ms/step - accuracy: 0.9851 - loss: 0.0277 - val_accuracy: 0.9840 - val_loss: 0.0309\n",
            "Epoch 9/10\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 43ms/step - accuracy: 0.9851 - loss: 0.0288 - val_accuracy: 0.9807 - val_loss: 0.0412\n",
            "Epoch 10/10\n",
            "\u001b[1m8146/8146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 43ms/step - accuracy: 0.9852 - loss: 0.0285 - val_accuracy: 0.9820 - val_loss: 0.0383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🌿 Step 7 — Evaluate the Model\n",
        "\n",
        "If you don’t have a separate test set, use the validation dataset for evaluation."
      ],
      "metadata": {
        "id": "cdgqNWztccAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(val_ds)\n",
        "print(f\"Validation Accuracy: {acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "QEsKxDNOcdiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🌿 Step 8 — Plot Accuracy and Loss Graphs"
      ],
      "metadata": {
        "id": "d9lODHcae1dJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Training & Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Z4PSEJoFjD4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🌿 Step 9 — Predictions and Confusion Matrix"
      ],
      "metadata": {
        "id": "NQ8BsCwJjLTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert val_ds into arrays\n",
        "y_true = np.concatenate([y for x, y in val_ds], axis=0)\n",
        "y_pred = np.argmax(model.predict(val_ds), axis=1)\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IeQHDv7ojM2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🌿 Step 10 — Save the Model"
      ],
      "metadata": {
        "id": "KEby8CS6jQWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"mobilenet_plant_disease_model.h5\")\n",
        "print(\"✅ Model saved as mobilenet_plant_disease_model.h5\")\n"
      ],
      "metadata": {
        "id": "XpmBCeqZjW0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🌿 Step 11 — Optional: View Model Parameters"
      ],
      "metadata": {
        "id": "FcOLpmxSjbfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_count = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
        "non_trainable_count = np.sum([np.prod(v.get_shape()) for v in model.non_trainable_weights])\n",
        "print(f\"Trainable params: {trainable_count:,}\")\n",
        "print(f\"Non-trainable params: {non_trainable_count:,}\")\n"
      ],
      "metadata": {
        "id": "edC1vj3pjfcu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}